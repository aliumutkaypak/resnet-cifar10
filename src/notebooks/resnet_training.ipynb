{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VIi6JeghfA0"
   },
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6oL5rmU684KS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rh1RE49dk46A"
   },
   "source": [
    "# Define training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "daazjLZok4ey"
   },
   "outputs": [],
   "source": [
    "# Dataset directories\n",
    "labeled_set_dir = 'data/cifar-10-batches-py'\n",
    "unlabeled_set_dir = 'data'\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 200\n",
    "\n",
    "# Output csv file\n",
    "output_csv_path = 'output.csv'\n",
    "\n",
    "# Checkpoint path\n",
    "checkpoint_path = 'model_2.pth'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRxu_aQVhnoz"
   },
   "source": [
    "# Define CIFAR10 Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9sIFWbEE7MAS"
   },
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data_dir, train=True, unlabeled=False, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.unlabeled = unlabeled\n",
    "        # Load all data batches\n",
    "        if unlabeled:\n",
    "          self.data, self.id = self.load_unlabeled_data()\n",
    "          self.labels = None\n",
    "        else:\n",
    "          self.data, self.labels = self.load_labeled_data()\n",
    "\n",
    "    def load_cifar_batch(self, file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            batch = pickle.load(fo, encoding='bytes')\n",
    "        return batch\n",
    "\n",
    "    def load_labeled_data(self):\n",
    "        data_batches = []\n",
    "        label_batches = []\n",
    "        if self.train:\n",
    "          for i in range(1, 6):\n",
    "            batch_file = os.path.join(self.data_dir, f'data_batch_{i}')\n",
    "            batch = self.load_cifar_batch(batch_file)\n",
    "            data_batches.append(batch[b'data'])\n",
    "            label_batches += batch[b'labels']\n",
    "        else:\n",
    "          batch_file = os.path.join(self.data_dir, f'test_batch')\n",
    "          batch = self.load_cifar_batch(batch_file)\n",
    "          data_batches.append(batch[b'data'])\n",
    "          label_batches += batch[b'labels']\n",
    "\n",
    "        data = np.vstack(data_batches).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "        labels = np.array(label_batches)\n",
    "        return data, labels\n",
    "\n",
    "    def load_unlabeled_data(self):\n",
    "        # Load the unlabeled batch\n",
    "        batch_file = os.path.join(self.data_dir, 'cifar_test_nolabels.pkl')\n",
    "        batch = self.load_cifar_batch(batch_file)\n",
    "        data = batch[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "        id = batch[b'ids'].tolist()\n",
    "        return data, id\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.unlabeled:\n",
    "          return len(self.labels)\n",
    "        else:\n",
    "          return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img = self.data[idx]\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if not self.unlabeled:\n",
    "          label = self.labels[idx]\n",
    "          return img, label\n",
    "        else:\n",
    "          return img, self.id[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NUrv6SCh0UW"
   },
   "source": [
    "# Define Resnet class. Changed version of the Resnet class in this repo: https://github.com/kuangliu/pytorch-cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lNSnNUnKi_d6"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "  expansion = 1\n",
    "\n",
    "  def __init__(self, in_planes, planes, stride=1):\n",
    "    super(BasicBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(\n",
    "        in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                            stride=1, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    self.shortcut = nn.Sequential()\n",
    "    if stride != 1 or in_planes != self.expansion*planes:\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                      kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(self.expansion*planes)\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.bn2(self.conv2(out))\n",
    "    out += self.shortcut(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "  def __init__(self, block, num_blocks, num_layers = 4, dropout= 0.3 ,num_channels=[64, 128, 256, 512] , avg_pool_kernel_s=4, num_classes=10):\n",
    "    super(ResNet, self).__init__()\n",
    "    assert len(num_channels) == num_layers\n",
    "    assert len(num_blocks) == num_layers\n",
    "    self.in_planes = 64\n",
    "    self.avg_pool_kernel_s = avg_pool_kernel_s\n",
    "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                            stride=1, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(64)\n",
    "    layers = []\n",
    "    for i in range(num_layers):\n",
    "      stride = 1 if i == 0 else 2\n",
    "      layers.append(nn.Dropout2d(p=dropout))\n",
    "      layers.append( self._make_layer(block, num_channels[i], num_blocks[i], stride=stride))\n",
    "    self.layers = nn.Sequential(*layers)\n",
    "    self.linear = nn.Linear(num_channels[-1]*block.expansion, num_classes)\n",
    "\n",
    "  def _make_layer(self, block, planes, num_blocks, stride):\n",
    "    strides = [stride] + [1]*(num_blocks-1)\n",
    "    layers = []\n",
    "    for stride in strides:\n",
    "        layers.append(block(self.in_planes, planes, stride))\n",
    "        self.in_planes = planes * block.expansion\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.layers(out)\n",
    "    out = F.avg_pool2d(out, self.avg_pool_kernel_s)\n",
    "    out = out.view(out.size(0), -1)\n",
    "    out = self.linear(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ENMDE4tx12x",
    "outputId": "47812efb-6877-4102-c4f0-85b1e41d8ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# If GPU available, the code uses it. Otherwise cpu is used for the training (not recommended).\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODmBAwVGw784"
   },
   "source": [
    "# Load dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RDmaYw8Rohnk"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_TEST = 1000\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = CIFAR10Dataset(labeled_set_dir, train=True, unlabeled=False, transform=transform)\n",
    "testset = CIFAR10Dataset(labeled_set_dir, train=False, unlabeled=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4un-sO_ijpm"
   },
   "source": [
    "## Create validation set from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5kVGBCe1vvPd"
   },
   "outputs": [],
   "source": [
    "total_size = len(trainset)\n",
    "train_size = int(0.9 * total_size)\n",
    "validation_size = total_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "trainset, validationset = torch.utils.data.random_split(trainset, [train_size, validation_size], generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpF-2GnaipuP"
   },
   "source": [
    "## Augment the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I3YCwu942W2J"
   },
   "outputs": [],
   "source": [
    "#Augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset.dataset.transform = train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqWZRKC6itri"
   },
   "source": [
    "## Create dataloader instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9btjqfl5yq6W"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE_TRAIN,shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE_TEST,shuffle=False,  num_workers=1)\n",
    "validation_loader = torch.utils.data.DataLoader(validationset,batch_size=BATCH_SIZE_TRAIN,shuffle=False,  num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cuwl03CkizmT"
   },
   "source": [
    "# Define training and evaluating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NrbAmDZpua0n"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, scheduler, data_loader, loss_history, criterion):\n",
    "  total_samples = len(data_loader.dataset)\n",
    "  model.train()\n",
    "  for i, (data, target) in enumerate(data_loader):\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "      print('[' + '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(total_samples) +\n",
    "      ' (' + '{:3.0f}'.format(100 * i / len(data_loader)) + '%)] Loss: ' +\n",
    "      '{:6.4f}'.format(loss.item()))\n",
    "  loss_history.append(loss.item())\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LtmwnJgk06_N"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, loss_history, criterion):\n",
    "  model.eval()\n",
    "  total_samples = len(data_loader.dataset)\n",
    "  correct_samples = 0\n",
    "  losses = []\n",
    "  with torch.no_grad():\n",
    "    for data, target in data_loader:\n",
    "      data = data.to(device)\n",
    "      target = target.to(device)\n",
    "      output = model(data)\n",
    "      loss = criterion(output, target)\n",
    "      _, pred = torch.max(output, dim=1)\n",
    "\n",
    "      losses.append(loss.item())\n",
    "      correct_samples += pred.eq(target).sum()\n",
    "\n",
    "  avg_loss = np.mean(losses)\n",
    "  loss_history.append(avg_loss)\n",
    "  print('\\nAverage test loss: ' + '{:.4f}'.format(avg_loss) +\n",
    "  ' Accuracy:' + '{:5}'.format(correct_samples) + '/' + '{:5}'.format(total_samples) + ' (' +\n",
    "  '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uia6PwY4jFEg"
   },
   "source": [
    "# Create model, optimizer, schedular, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ouhj4UI2RLS",
    "outputId": "18a9904b-3c36-4d3c-dea5-4cae64bab6d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "         Dropout2d-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "            Conv2d-6           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-8           [-1, 64, 32, 32]               0\n",
      "            Conv2d-9           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 32, 32]             128\n",
      "           Conv2d-11           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-12           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-13           [-1, 64, 32, 32]               0\n",
      "        Dropout2d-14           [-1, 64, 32, 32]               0\n",
      "           Conv2d-15          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "           Conv2d-19          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-21          [-1, 128, 16, 16]               0\n",
      "        Dropout2d-22          [-1, 128, 16, 16]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "           Conv2d-25            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-29            [-1, 256, 8, 8]               0\n",
      "        Dropout2d-30            [-1, 256, 8, 8]               0\n",
      "           Conv2d-31            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-33            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-34            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-35            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-36            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-37            [-1, 512, 4, 4]               0\n",
      "           Linear-38                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 4,977,226\n",
      "Trainable params: 4,977,226\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 10.44\n",
      "Params size (MB): 18.99\n",
      "Estimated Total Size (MB): 29.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock, [2, 1, 1, 1], num_layers = 4, dropout= 0.0 ,num_channels=[64, 128, 256, 512] , avg_pool_kernel_s=4, num_classes=10)\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1,\n",
    "                            momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)  # eta_min is the minimum lr\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCaMaVVCjIUn"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8EhRWr6pSIn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/45000 (  0%)] Loss: 2.4139\n",
      "[12800/45000 ( 28%)] Loss: 1.6829\n",
      "[25600/45000 ( 57%)] Loss: 1.6109\n",
      "[38400/45000 ( 85%)] Loss: 1.3513\n",
      "\n",
      "Average test loss: 1.4810 Accuracy: 2335/ 5000 (46.70%)\n",
      "\n",
      "Epoch: 2\n",
      "[    0/45000 (  0%)] Loss: 1.2529\n",
      "[12800/45000 ( 28%)] Loss: 1.2779\n",
      "[25600/45000 ( 57%)] Loss: 1.2632\n",
      "[38400/45000 ( 85%)] Loss: 0.9780\n",
      "\n",
      "Average test loss: 1.1586 Accuracy: 2929/ 5000 (58.58%)\n",
      "\n",
      "Epoch: 3\n",
      "[    0/45000 (  0%)] Loss: 1.1641\n",
      "[12800/45000 ( 28%)] Loss: 1.0826\n",
      "[25600/45000 ( 57%)] Loss: 1.0388\n",
      "[38400/45000 ( 85%)] Loss: 1.0573\n",
      "\n",
      "Average test loss: 1.1509 Accuracy: 2894/ 5000 (57.88%)\n",
      "\n",
      "Epoch: 4\n",
      "[    0/45000 (  0%)] Loss: 0.8318\n",
      "[12800/45000 ( 28%)] Loss: 0.8798\n",
      "[25600/45000 ( 57%)] Loss: 0.8651\n",
      "[38400/45000 ( 85%)] Loss: 0.8487\n",
      "\n",
      "Average test loss: 1.1429 Accuracy: 3072/ 5000 (61.44%)\n",
      "\n",
      "Epoch: 5\n",
      "[    0/45000 (  0%)] Loss: 0.6885\n",
      "[12800/45000 ( 28%)] Loss: 0.8205\n",
      "[25600/45000 ( 57%)] Loss: 0.6329\n",
      "[38400/45000 ( 85%)] Loss: 0.7248\n",
      "\n",
      "Average test loss: 0.8282 Accuracy: 3547/ 5000 (70.94%)\n",
      "\n",
      "Epoch: 6\n",
      "[    0/45000 (  0%)] Loss: 0.6301\n",
      "[12800/45000 ( 28%)] Loss: 0.5666\n",
      "[25600/45000 ( 57%)] Loss: 0.6324\n",
      "[38400/45000 ( 85%)] Loss: 0.7307\n",
      "\n",
      "Average test loss: 0.8433 Accuracy: 3537/ 5000 (70.74%)\n",
      "\n",
      "Epoch: 7\n",
      "[    0/45000 (  0%)] Loss: 0.7302\n",
      "[12800/45000 ( 28%)] Loss: 0.6694\n",
      "[25600/45000 ( 57%)] Loss: 0.6224\n",
      "[38400/45000 ( 85%)] Loss: 0.7020\n",
      "\n",
      "Average test loss: 0.6974 Accuracy: 3777/ 5000 (75.54%)\n",
      "\n",
      "Epoch: 8\n",
      "[    0/45000 (  0%)] Loss: 0.6303\n",
      "[12800/45000 ( 28%)] Loss: 0.6165\n",
      "[25600/45000 ( 57%)] Loss: 0.5381\n",
      "[38400/45000 ( 85%)] Loss: 0.6517\n",
      "\n",
      "Average test loss: 0.8515 Accuracy: 3534/ 5000 (70.68%)\n",
      "\n",
      "Epoch: 9\n",
      "[    0/45000 (  0%)] Loss: 0.6951\n",
      "[12800/45000 ( 28%)] Loss: 0.8234\n",
      "[25600/45000 ( 57%)] Loss: 0.5505\n",
      "[38400/45000 ( 85%)] Loss: 0.8204\n",
      "\n",
      "Average test loss: 0.7881 Accuracy: 3645/ 5000 (72.90%)\n",
      "\n",
      "Epoch: 10\n",
      "[    0/45000 (  0%)] Loss: 0.5353\n",
      "[12800/45000 ( 28%)] Loss: 0.6966\n",
      "[25600/45000 ( 57%)] Loss: 0.6485\n",
      "[38400/45000 ( 85%)] Loss: 0.5143\n",
      "\n",
      "Average test loss: 0.8504 Accuracy: 3636/ 5000 (72.72%)\n",
      "\n",
      "Epoch: 11\n",
      "[    0/45000 (  0%)] Loss: 0.5305\n",
      "[12800/45000 ( 28%)] Loss: 0.6113\n",
      "[25600/45000 ( 57%)] Loss: 0.6142\n",
      "[38400/45000 ( 85%)] Loss: 0.6562\n",
      "\n",
      "Average test loss: 0.9553 Accuracy: 3476/ 5000 (69.52%)\n",
      "\n",
      "Epoch: 12\n",
      "[    0/45000 (  0%)] Loss: 0.5371\n",
      "[12800/45000 ( 28%)] Loss: 0.5535\n",
      "[25600/45000 ( 57%)] Loss: 0.4989\n",
      "[38400/45000 ( 85%)] Loss: 0.5134\n",
      "\n",
      "Average test loss: 0.7198 Accuracy: 3732/ 5000 (74.64%)\n",
      "\n",
      "Epoch: 13\n",
      "[    0/45000 (  0%)] Loss: 0.6703\n",
      "[12800/45000 ( 28%)] Loss: 0.4770\n",
      "[25600/45000 ( 57%)] Loss: 0.4141\n",
      "[38400/45000 ( 85%)] Loss: 0.5240\n",
      "\n",
      "Average test loss: 0.7039 Accuracy: 3764/ 5000 (75.28%)\n",
      "\n",
      "Epoch: 14\n",
      "[    0/45000 (  0%)] Loss: 0.6428\n",
      "[12800/45000 ( 28%)] Loss: 0.5897\n",
      "[25600/45000 ( 57%)] Loss: 0.5413\n",
      "[38400/45000 ( 85%)] Loss: 0.4400\n",
      "\n",
      "Average test loss: 0.7281 Accuracy: 3764/ 5000 (75.28%)\n",
      "\n",
      "Epoch: 15\n",
      "[    0/45000 (  0%)] Loss: 0.5923\n",
      "[12800/45000 ( 28%)] Loss: 0.5833\n",
      "[25600/45000 ( 57%)] Loss: 0.5481\n",
      "[38400/45000 ( 85%)] Loss: 0.5575\n",
      "\n",
      "Average test loss: 0.6073 Accuracy: 3939/ 5000 (78.78%)\n",
      "\n",
      "Epoch: 16\n",
      "[    0/45000 (  0%)] Loss: 0.5000\n",
      "[12800/45000 ( 28%)] Loss: 0.5216\n",
      "[25600/45000 ( 57%)] Loss: 0.4977\n",
      "[38400/45000 ( 85%)] Loss: 0.5189\n",
      "\n",
      "Average test loss: 0.8009 Accuracy: 3597/ 5000 (71.94%)\n",
      "\n",
      "Epoch: 17\n",
      "[    0/45000 (  0%)] Loss: 0.4019\n",
      "[12800/45000 ( 28%)] Loss: 0.3882\n",
      "[25600/45000 ( 57%)] Loss: 0.4969\n",
      "[38400/45000 ( 85%)] Loss: 0.6692\n",
      "\n",
      "Average test loss: 0.7676 Accuracy: 3701/ 5000 (74.02%)\n",
      "\n",
      "Epoch: 18\n",
      "[    0/45000 (  0%)] Loss: 0.5700\n",
      "[12800/45000 ( 28%)] Loss: 0.5369\n",
      "[25600/45000 ( 57%)] Loss: 0.3626\n",
      "[38400/45000 ( 85%)] Loss: 0.4432\n",
      "\n",
      "Average test loss: 0.6195 Accuracy: 3931/ 5000 (78.62%)\n",
      "\n",
      "Epoch: 19\n",
      "[    0/45000 (  0%)] Loss: 0.4929\n",
      "[12800/45000 ( 28%)] Loss: 0.5052\n",
      "[25600/45000 ( 57%)] Loss: 0.4643\n",
      "[38400/45000 ( 85%)] Loss: 0.4427\n",
      "\n",
      "Average test loss: 0.7346 Accuracy: 3815/ 5000 (76.30%)\n",
      "\n",
      "Epoch: 20\n",
      "[    0/45000 (  0%)] Loss: 0.4815\n",
      "[12800/45000 ( 28%)] Loss: 0.4466\n",
      "[25600/45000 ( 57%)] Loss: 0.5296\n",
      "[38400/45000 ( 85%)] Loss: 0.4674\n",
      "\n",
      "Average test loss: 0.7346 Accuracy: 3784/ 5000 (75.68%)\n",
      "\n",
      "Epoch: 21\n",
      "[    0/45000 (  0%)] Loss: 0.4425\n",
      "[12800/45000 ( 28%)] Loss: 0.5160\n",
      "[25600/45000 ( 57%)] Loss: 0.5343\n",
      "[38400/45000 ( 85%)] Loss: 0.5851\n",
      "\n",
      "Average test loss: 0.5519 Accuracy: 4041/ 5000 (80.82%)\n",
      "\n",
      "Epoch: 22\n",
      "[    0/45000 (  0%)] Loss: 0.3788\n",
      "[12800/45000 ( 28%)] Loss: 0.4928\n",
      "[25600/45000 ( 57%)] Loss: 0.5075\n",
      "[38400/45000 ( 85%)] Loss: 0.4631\n",
      "\n",
      "Average test loss: 0.6038 Accuracy: 3961/ 5000 (79.22%)\n",
      "\n",
      "Epoch: 23\n",
      "[    0/45000 (  0%)] Loss: 0.4662\n",
      "[12800/45000 ( 28%)] Loss: 0.5015\n",
      "[25600/45000 ( 57%)] Loss: 0.5934\n",
      "[38400/45000 ( 85%)] Loss: 0.4530\n",
      "\n",
      "Average test loss: 0.8582 Accuracy: 3538/ 5000 (70.76%)\n",
      "\n",
      "Epoch: 24\n",
      "[    0/45000 (  0%)] Loss: 0.4761\n",
      "[12800/45000 ( 28%)] Loss: 0.4193\n",
      "[25600/45000 ( 57%)] Loss: 0.3940\n",
      "[38400/45000 ( 85%)] Loss: 0.4657\n",
      "\n",
      "Average test loss: 0.6706 Accuracy: 3836/ 5000 (76.72%)\n",
      "\n",
      "Epoch: 25\n",
      "[    0/45000 (  0%)] Loss: 0.4846\n",
      "[12800/45000 ( 28%)] Loss: 0.4555\n",
      "[25600/45000 ( 57%)] Loss: 0.5211\n",
      "[38400/45000 ( 85%)] Loss: 0.4247\n",
      "\n",
      "Average test loss: 0.6440 Accuracy: 3852/ 5000 (77.04%)\n",
      "\n",
      "Epoch: 26\n",
      "[    0/45000 (  0%)] Loss: 0.3881\n",
      "[12800/45000 ( 28%)] Loss: 0.4485\n",
      "[25600/45000 ( 57%)] Loss: 0.4025\n",
      "[38400/45000 ( 85%)] Loss: 0.5147\n",
      "\n",
      "Average test loss: 0.6104 Accuracy: 3927/ 5000 (78.54%)\n",
      "\n",
      "Epoch: 27\n",
      "[    0/45000 (  0%)] Loss: 0.4554\n",
      "[12800/45000 ( 28%)] Loss: 0.5270\n",
      "[25600/45000 ( 57%)] Loss: 0.5259\n",
      "[38400/45000 ( 85%)] Loss: 0.5325\n",
      "\n",
      "Average test loss: 0.7433 Accuracy: 3705/ 5000 (74.10%)\n",
      "\n",
      "Epoch: 28\n",
      "[    0/45000 (  0%)] Loss: 0.3193\n",
      "[12800/45000 ( 28%)] Loss: 0.6709\n",
      "[25600/45000 ( 57%)] Loss: 0.4216\n",
      "[38400/45000 ( 85%)] Loss: 0.3949\n",
      "\n",
      "Average test loss: 0.5249 Accuracy: 4085/ 5000 (81.70%)\n",
      "\n",
      "Epoch: 29\n",
      "[    0/45000 (  0%)] Loss: 0.4365\n",
      "[12800/45000 ( 28%)] Loss: 0.4818\n",
      "[25600/45000 ( 57%)] Loss: 0.3729\n",
      "[38400/45000 ( 85%)] Loss: 0.5375\n",
      "\n",
      "Average test loss: 0.6110 Accuracy: 3888/ 5000 (77.76%)\n",
      "\n",
      "Epoch: 30\n",
      "[    0/45000 (  0%)] Loss: 0.4282\n",
      "[12800/45000 ( 28%)] Loss: 0.3750\n",
      "[25600/45000 ( 57%)] Loss: 0.4447\n",
      "[38400/45000 ( 85%)] Loss: 0.3479\n",
      "\n",
      "Average test loss: 0.5516 Accuracy: 4061/ 5000 (81.22%)\n",
      "\n",
      "Epoch: 31\n",
      "[    0/45000 (  0%)] Loss: 0.3505\n",
      "[12800/45000 ( 28%)] Loss: 0.3295\n",
      "[25600/45000 ( 57%)] Loss: 0.4562\n",
      "[38400/45000 ( 85%)] Loss: 0.5225\n",
      "\n",
      "Average test loss: 0.5991 Accuracy: 3956/ 5000 (79.12%)\n",
      "\n",
      "Epoch: 32\n",
      "[    0/45000 (  0%)] Loss: 0.4442\n",
      "[12800/45000 ( 28%)] Loss: 0.4332\n",
      "[25600/45000 ( 57%)] Loss: 0.3675\n",
      "[38400/45000 ( 85%)] Loss: 0.4031\n",
      "\n",
      "Average test loss: 0.6522 Accuracy: 3925/ 5000 (78.50%)\n",
      "\n",
      "Epoch: 33\n",
      "[    0/45000 (  0%)] Loss: 0.5324\n",
      "[12800/45000 ( 28%)] Loss: 0.4059\n",
      "[25600/45000 ( 57%)] Loss: 0.5944\n",
      "[38400/45000 ( 85%)] Loss: 0.3411\n",
      "\n",
      "Average test loss: 0.7850 Accuracy: 3705/ 5000 (74.10%)\n",
      "\n",
      "Epoch: 34\n",
      "[    0/45000 (  0%)] Loss: 0.3580\n",
      "[12800/45000 ( 28%)] Loss: 0.3921\n",
      "[25600/45000 ( 57%)] Loss: 0.4202\n",
      "[38400/45000 ( 85%)] Loss: 0.4579\n",
      "\n",
      "Average test loss: 0.5723 Accuracy: 4007/ 5000 (80.14%)\n",
      "\n",
      "Epoch: 35\n",
      "[    0/45000 (  0%)] Loss: 0.4424\n",
      "[12800/45000 ( 28%)] Loss: 0.3737\n",
      "[25600/45000 ( 57%)] Loss: 0.4521\n",
      "[38400/45000 ( 85%)] Loss: 0.5311\n",
      "\n",
      "Average test loss: 0.5303 Accuracy: 4048/ 5000 (80.96%)\n",
      "\n",
      "Epoch: 36\n",
      "[    0/45000 (  0%)] Loss: 0.3769\n",
      "[12800/45000 ( 28%)] Loss: 0.4361\n",
      "[25600/45000 ( 57%)] Loss: 0.3156\n",
      "[38400/45000 ( 85%)] Loss: 0.3183\n",
      "\n",
      "Average test loss: 0.5433 Accuracy: 4080/ 5000 (81.60%)\n",
      "\n",
      "Epoch: 37\n",
      "[    0/45000 (  0%)] Loss: 0.3797\n",
      "[12800/45000 ( 28%)] Loss: 0.3192\n",
      "[25600/45000 ( 57%)] Loss: 0.4530\n",
      "[38400/45000 ( 85%)] Loss: 0.4383\n",
      "\n",
      "Average test loss: 0.5955 Accuracy: 3997/ 5000 (79.94%)\n",
      "\n",
      "Epoch: 38\n",
      "[    0/45000 (  0%)] Loss: 0.4807\n",
      "[12800/45000 ( 28%)] Loss: 0.3994\n",
      "[25600/45000 ( 57%)] Loss: 0.3692\n",
      "[38400/45000 ( 85%)] Loss: 0.5308\n",
      "\n",
      "Average test loss: 0.6904 Accuracy: 3840/ 5000 (76.80%)\n",
      "\n",
      "Epoch: 39\n",
      "[    0/45000 (  0%)] Loss: 0.3494\n",
      "[12800/45000 ( 28%)] Loss: 0.4292\n",
      "[25600/45000 ( 57%)] Loss: 0.5126\n",
      "[38400/45000 ( 85%)] Loss: 0.4123\n",
      "\n",
      "Average test loss: 0.5368 Accuracy: 4053/ 5000 (81.06%)\n",
      "\n",
      "Epoch: 40\n",
      "[    0/45000 (  0%)] Loss: 0.4833\n",
      "[12800/45000 ( 28%)] Loss: 0.4695\n",
      "[25600/45000 ( 57%)] Loss: 0.5229\n",
      "[38400/45000 ( 85%)] Loss: 0.4612\n",
      "\n",
      "Average test loss: 0.7368 Accuracy: 3771/ 5000 (75.42%)\n",
      "\n",
      "Epoch: 41\n",
      "[    0/45000 (  0%)] Loss: 0.3642\n",
      "[12800/45000 ( 28%)] Loss: 0.4975\n",
      "[25600/45000 ( 57%)] Loss: 0.4118\n",
      "[38400/45000 ( 85%)] Loss: 0.3450\n",
      "\n",
      "Average test loss: 0.4865 Accuracy: 4141/ 5000 (82.82%)\n",
      "\n",
      "Epoch: 42\n",
      "[    0/45000 (  0%)] Loss: 0.4210\n",
      "[12800/45000 ( 28%)] Loss: 0.3721\n",
      "[25600/45000 ( 57%)] Loss: 0.4085\n",
      "[38400/45000 ( 85%)] Loss: 0.4742\n",
      "\n",
      "Average test loss: 0.5315 Accuracy: 4057/ 5000 (81.14%)\n",
      "\n",
      "Epoch: 43\n",
      "[    0/45000 (  0%)] Loss: 0.2941\n",
      "[12800/45000 ( 28%)] Loss: 0.5828\n",
      "[25600/45000 ( 57%)] Loss: 0.4429\n",
      "[38400/45000 ( 85%)] Loss: 0.4217\n",
      "\n",
      "Average test loss: 0.6168 Accuracy: 3987/ 5000 (79.74%)\n",
      "\n",
      "Epoch: 44\n",
      "[    0/45000 (  0%)] Loss: 0.5302\n",
      "[12800/45000 ( 28%)] Loss: 0.2406\n",
      "[25600/45000 ( 57%)] Loss: 0.3415\n",
      "[38400/45000 ( 85%)] Loss: 0.5421\n",
      "\n",
      "Average test loss: 0.5845 Accuracy: 3997/ 5000 (79.94%)\n",
      "\n",
      "Epoch: 45\n",
      "[    0/45000 (  0%)] Loss: 0.4357\n",
      "[12800/45000 ( 28%)] Loss: 0.4517\n",
      "[25600/45000 ( 57%)] Loss: 0.3410\n",
      "[38400/45000 ( 85%)] Loss: 0.4030\n",
      "\n",
      "Average test loss: 0.4907 Accuracy: 4147/ 5000 (82.94%)\n",
      "\n",
      "Epoch: 46\n",
      "[    0/45000 (  0%)] Loss: 0.3400\n",
      "[12800/45000 ( 28%)] Loss: 0.5459\n",
      "[25600/45000 ( 57%)] Loss: 0.4194\n",
      "[38400/45000 ( 85%)] Loss: 0.3866\n",
      "\n",
      "Average test loss: 0.7181 Accuracy: 3866/ 5000 (77.32%)\n",
      "\n",
      "Epoch: 47\n",
      "[    0/45000 (  0%)] Loss: 0.4136\n",
      "[12800/45000 ( 28%)] Loss: 0.4609\n",
      "[25600/45000 ( 57%)] Loss: 0.6317\n",
      "[38400/45000 ( 85%)] Loss: 0.4126\n",
      "\n",
      "Average test loss: 0.5824 Accuracy: 4009/ 5000 (80.18%)\n",
      "\n",
      "Epoch: 48\n",
      "[    0/45000 (  0%)] Loss: 0.4315\n",
      "[12800/45000 ( 28%)] Loss: 0.4936\n",
      "[25600/45000 ( 57%)] Loss: 0.4969\n",
      "[38400/45000 ( 85%)] Loss: 0.4083\n",
      "\n",
      "Average test loss: 0.7763 Accuracy: 3794/ 5000 (75.88%)\n",
      "\n",
      "Epoch: 49\n",
      "[    0/45000 (  0%)] Loss: 0.4588\n",
      "[12800/45000 ( 28%)] Loss: 0.4148\n",
      "[25600/45000 ( 57%)] Loss: 0.3711\n",
      "[38400/45000 ( 85%)] Loss: 0.4066\n",
      "\n",
      "Average test loss: 0.7841 Accuracy: 3720/ 5000 (74.40%)\n",
      "\n",
      "Epoch: 50\n",
      "[    0/45000 (  0%)] Loss: 0.3582\n",
      "[12800/45000 ( 28%)] Loss: 0.2866\n",
      "[25600/45000 ( 57%)] Loss: 0.4344\n",
      "[38400/45000 ( 85%)] Loss: 0.2950\n",
      "\n",
      "Average test loss: 0.6060 Accuracy: 4008/ 5000 (80.16%)\n",
      "\n",
      "Epoch: 51\n",
      "[    0/45000 (  0%)] Loss: 0.3549\n",
      "[12800/45000 ( 28%)] Loss: 0.3836\n",
      "[25600/45000 ( 57%)] Loss: 0.4850\n",
      "[38400/45000 ( 85%)] Loss: 0.4400\n",
      "\n",
      "Average test loss: 0.5283 Accuracy: 4107/ 5000 (82.14%)\n",
      "\n",
      "Epoch: 52\n",
      "[    0/45000 (  0%)] Loss: 0.2622\n",
      "[12800/45000 ( 28%)] Loss: 0.5770\n",
      "[25600/45000 ( 57%)] Loss: 0.3383\n",
      "[38400/45000 ( 85%)] Loss: 0.2534\n",
      "\n",
      "Average test loss: 0.8411 Accuracy: 3655/ 5000 (73.10%)\n",
      "\n",
      "Epoch: 53\n",
      "[    0/45000 (  0%)] Loss: 0.3717\n",
      "[12800/45000 ( 28%)] Loss: 0.4741\n",
      "[25600/45000 ( 57%)] Loss: 0.2387\n",
      "[38400/45000 ( 85%)] Loss: 0.4537\n",
      "\n",
      "Average test loss: 0.7005 Accuracy: 3795/ 5000 (75.90%)\n",
      "\n",
      "Epoch: 54\n",
      "[    0/45000 (  0%)] Loss: 0.4434\n",
      "[12800/45000 ( 28%)] Loss: 0.3456\n",
      "[25600/45000 ( 57%)] Loss: 0.3400\n",
      "[38400/45000 ( 85%)] Loss: 0.4137\n",
      "\n",
      "Average test loss: 0.5823 Accuracy: 4016/ 5000 (80.32%)\n",
      "\n",
      "Epoch: 55\n",
      "[    0/45000 (  0%)] Loss: 0.3915\n",
      "[12800/45000 ( 28%)] Loss: 0.4956\n",
      "[25600/45000 ( 57%)] Loss: 0.3882\n",
      "[38400/45000 ( 85%)] Loss: 0.4043\n",
      "\n",
      "Average test loss: 0.5975 Accuracy: 4001/ 5000 (80.02%)\n",
      "\n",
      "Epoch: 56\n",
      "[    0/45000 (  0%)] Loss: 0.4161\n",
      "[12800/45000 ( 28%)] Loss: 0.6143\n",
      "[25600/45000 ( 57%)] Loss: 0.3488\n",
      "[38400/45000 ( 85%)] Loss: 0.3053\n",
      "\n",
      "Average test loss: 0.5432 Accuracy: 4080/ 5000 (81.60%)\n",
      "\n",
      "Epoch: 57\n",
      "[    0/45000 (  0%)] Loss: 0.3643\n",
      "[12800/45000 ( 28%)] Loss: 0.4780\n",
      "[25600/45000 ( 57%)] Loss: 0.3115\n",
      "[38400/45000 ( 85%)] Loss: 0.4822\n",
      "\n",
      "Average test loss: 0.6137 Accuracy: 3929/ 5000 (78.58%)\n",
      "\n",
      "Epoch: 58\n",
      "[    0/45000 (  0%)] Loss: 0.3312\n",
      "[12800/45000 ( 28%)] Loss: 0.5131\n",
      "[25600/45000 ( 57%)] Loss: 0.4180\n",
      "[38400/45000 ( 85%)] Loss: 0.3023\n",
      "\n",
      "Average test loss: 0.6187 Accuracy: 3931/ 5000 (78.62%)\n",
      "\n",
      "Epoch: 59\n",
      "[    0/45000 (  0%)] Loss: 0.3251\n",
      "[12800/45000 ( 28%)] Loss: 0.2794\n",
      "[25600/45000 ( 57%)] Loss: 0.2638\n",
      "[38400/45000 ( 85%)] Loss: 0.3684\n",
      "\n",
      "Average test loss: 0.5538 Accuracy: 4026/ 5000 (80.52%)\n",
      "\n",
      "Epoch: 60\n",
      "[    0/45000 (  0%)] Loss: 0.4286\n",
      "[12800/45000 ( 28%)] Loss: 0.3761\n",
      "[25600/45000 ( 57%)] Loss: 0.3859\n",
      "[38400/45000 ( 85%)] Loss: 0.3784\n",
      "\n",
      "Average test loss: 0.5037 Accuracy: 4142/ 5000 (82.84%)\n",
      "\n",
      "Epoch: 61\n",
      "[    0/45000 (  0%)] Loss: 0.2418\n",
      "[12800/45000 ( 28%)] Loss: 0.3875\n",
      "[25600/45000 ( 57%)] Loss: 0.3053\n",
      "[38400/45000 ( 85%)] Loss: 0.3651\n",
      "\n",
      "Average test loss: 0.5140 Accuracy: 4093/ 5000 (81.86%)\n",
      "\n",
      "Epoch: 62\n",
      "[    0/45000 (  0%)] Loss: 0.2975\n",
      "[12800/45000 ( 28%)] Loss: 0.3489\n",
      "[25600/45000 ( 57%)] Loss: 0.3900\n",
      "[38400/45000 ( 85%)] Loss: 0.4096\n",
      "\n",
      "Average test loss: 0.5862 Accuracy: 4014/ 5000 (80.28%)\n",
      "\n",
      "Epoch: 63\n",
      "[    0/45000 (  0%)] Loss: 0.3605\n",
      "[12800/45000 ( 28%)] Loss: 0.2715\n",
      "[25600/45000 ( 57%)] Loss: 0.3508\n",
      "[38400/45000 ( 85%)] Loss: 0.2897\n",
      "\n",
      "Average test loss: 0.5528 Accuracy: 4051/ 5000 (81.02%)\n",
      "\n",
      "Epoch: 64\n",
      "[    0/45000 (  0%)] Loss: 0.3910\n",
      "[12800/45000 ( 28%)] Loss: 0.3369\n",
      "[25600/45000 ( 57%)] Loss: 0.3541\n",
      "[38400/45000 ( 85%)] Loss: 0.2926\n",
      "\n",
      "Average test loss: 0.6156 Accuracy: 3952/ 5000 (79.04%)\n",
      "\n",
      "Epoch: 65\n",
      "[    0/45000 (  0%)] Loss: 0.4000\n",
      "[12800/45000 ( 28%)] Loss: 0.3447\n",
      "[25600/45000 ( 57%)] Loss: 0.3275\n",
      "[38400/45000 ( 85%)] Loss: 0.3608\n",
      "\n",
      "Average test loss: 0.4770 Accuracy: 4182/ 5000 (83.64%)\n",
      "\n",
      "Epoch: 66\n",
      "[    0/45000 (  0%)] Loss: 0.5242\n",
      "[12800/45000 ( 28%)] Loss: 0.3599\n",
      "[25600/45000 ( 57%)] Loss: 0.4089\n",
      "[38400/45000 ( 85%)] Loss: 0.2628\n",
      "\n",
      "Average test loss: 0.5598 Accuracy: 4050/ 5000 (81.00%)\n",
      "\n",
      "Epoch: 67\n",
      "[    0/45000 (  0%)] Loss: 0.2892\n",
      "[12800/45000 ( 28%)] Loss: 0.3646\n",
      "[25600/45000 ( 57%)] Loss: 0.3659\n",
      "[38400/45000 ( 85%)] Loss: 0.2995\n",
      "\n",
      "Average test loss: 0.5581 Accuracy: 4022/ 5000 (80.44%)\n",
      "\n",
      "Epoch: 68\n",
      "[    0/45000 (  0%)] Loss: 0.3455\n",
      "[12800/45000 ( 28%)] Loss: 0.3999\n",
      "[25600/45000 ( 57%)] Loss: 0.3904\n",
      "[38400/45000 ( 85%)] Loss: 0.4278\n",
      "\n",
      "Average test loss: 0.5125 Accuracy: 4153/ 5000 (83.06%)\n",
      "\n",
      "Epoch: 69\n",
      "[    0/45000 (  0%)] Loss: 0.3565\n",
      "[12800/45000 ( 28%)] Loss: 0.4357\n",
      "[25600/45000 ( 57%)] Loss: 0.3634\n",
      "[38400/45000 ( 85%)] Loss: 0.4406\n",
      "\n",
      "Average test loss: 0.5280 Accuracy: 4107/ 5000 (82.14%)\n",
      "\n",
      "Epoch: 70\n",
      "[    0/45000 (  0%)] Loss: 0.3338\n",
      "[12800/45000 ( 28%)] Loss: 0.2137\n",
      "[25600/45000 ( 57%)] Loss: 0.1566\n",
      "[38400/45000 ( 85%)] Loss: 0.3621\n",
      "\n",
      "Average test loss: 0.4835 Accuracy: 4182/ 5000 (83.64%)\n",
      "\n",
      "Epoch: 71\n",
      "[    0/45000 (  0%)] Loss: 0.2024\n",
      "[12800/45000 ( 28%)] Loss: 0.3343\n",
      "[25600/45000 ( 57%)] Loss: 0.3315\n",
      "[38400/45000 ( 85%)] Loss: 0.2022\n",
      "\n",
      "Average test loss: 0.5648 Accuracy: 4053/ 5000 (81.06%)\n",
      "\n",
      "Epoch: 72\n",
      "[    0/45000 (  0%)] Loss: 0.4121\n",
      "[12800/45000 ( 28%)] Loss: 0.4515\n",
      "[25600/45000 ( 57%)] Loss: 0.3135\n",
      "[38400/45000 ( 85%)] Loss: 0.4359\n",
      "\n",
      "Average test loss: 0.4870 Accuracy: 4136/ 5000 (82.72%)\n",
      "\n",
      "Epoch: 73\n",
      "[    0/45000 (  0%)] Loss: 0.4156\n",
      "[12800/45000 ( 28%)] Loss: 0.3800\n",
      "[25600/45000 ( 57%)] Loss: 0.2842\n",
      "[38400/45000 ( 85%)] Loss: 0.2357\n",
      "\n",
      "Average test loss: 0.6345 Accuracy: 3917/ 5000 (78.34%)\n",
      "\n",
      "Epoch: 74\n",
      "[    0/45000 (  0%)] Loss: 0.3180\n",
      "[12800/45000 ( 28%)] Loss: 0.3710\n",
      "[25600/45000 ( 57%)] Loss: 0.5251\n",
      "[38400/45000 ( 85%)] Loss: 0.5264\n",
      "\n",
      "Average test loss: 0.6149 Accuracy: 3925/ 5000 (78.50%)\n",
      "\n",
      "Epoch: 75\n",
      "[    0/45000 (  0%)] Loss: 0.2828\n",
      "[12800/45000 ( 28%)] Loss: 0.2880\n",
      "[25600/45000 ( 57%)] Loss: 0.3300\n",
      "[38400/45000 ( 85%)] Loss: 0.2091\n",
      "\n",
      "Average test loss: 0.4897 Accuracy: 4145/ 5000 (82.90%)\n",
      "\n",
      "Epoch: 76\n",
      "[    0/45000 (  0%)] Loss: 0.3174\n",
      "[12800/45000 ( 28%)] Loss: 0.4042\n",
      "[25600/45000 ( 57%)] Loss: 0.5230\n",
      "[38400/45000 ( 85%)] Loss: 0.2555\n",
      "\n",
      "Average test loss: 0.4957 Accuracy: 4191/ 5000 (83.82%)\n",
      "\n",
      "Epoch: 77\n",
      "[    0/45000 (  0%)] Loss: 0.3840\n",
      "[12800/45000 ( 28%)] Loss: 0.3820\n",
      "[25600/45000 ( 57%)] Loss: 0.3918\n",
      "[38400/45000 ( 85%)] Loss: 0.2862\n",
      "\n",
      "Average test loss: 0.4497 Accuracy: 4208/ 5000 (84.16%)\n",
      "\n",
      "Epoch: 78\n",
      "[    0/45000 (  0%)] Loss: 0.3367\n",
      "[12800/45000 ( 28%)] Loss: 0.3182\n",
      "[25600/45000 ( 57%)] Loss: 0.5304\n",
      "[38400/45000 ( 85%)] Loss: 0.4043\n",
      "\n",
      "Average test loss: 0.4669 Accuracy: 4200/ 5000 (84.00%)\n",
      "\n",
      "Epoch: 79\n",
      "[    0/45000 (  0%)] Loss: 0.4111\n",
      "[12800/45000 ( 28%)] Loss: 0.3036\n",
      "[25600/45000 ( 57%)] Loss: 0.2806\n",
      "[38400/45000 ( 85%)] Loss: 0.4326\n",
      "\n",
      "Average test loss: 0.4523 Accuracy: 4216/ 5000 (84.32%)\n",
      "\n",
      "Epoch: 80\n",
      "[    0/45000 (  0%)] Loss: 0.2392\n",
      "[12800/45000 ( 28%)] Loss: 0.3671\n",
      "[25600/45000 ( 57%)] Loss: 0.3077\n",
      "[38400/45000 ( 85%)] Loss: 0.3357\n",
      "\n",
      "Average test loss: 0.5454 Accuracy: 4060/ 5000 (81.20%)\n",
      "\n",
      "Epoch: 81\n",
      "[    0/45000 (  0%)] Loss: 0.4684\n",
      "[12800/45000 ( 28%)] Loss: 0.3742\n",
      "[25600/45000 ( 57%)] Loss: 0.2340\n",
      "[38400/45000 ( 85%)] Loss: 0.2983\n",
      "\n",
      "Average test loss: 0.5734 Accuracy: 4028/ 5000 (80.56%)\n",
      "\n",
      "Epoch: 82\n",
      "[    0/45000 (  0%)] Loss: 0.3798\n",
      "[12800/45000 ( 28%)] Loss: 0.2757\n",
      "[25600/45000 ( 57%)] Loss: 0.4028\n",
      "[38400/45000 ( 85%)] Loss: 0.4547\n",
      "\n",
      "Average test loss: 0.4168 Accuracy: 4244/ 5000 (84.88%)\n",
      "\n",
      "Epoch: 83\n",
      "[    0/45000 (  0%)] Loss: 0.2568\n",
      "[12800/45000 ( 28%)] Loss: 0.2601\n",
      "[25600/45000 ( 57%)] Loss: 0.3233\n",
      "[38400/45000 ( 85%)] Loss: 0.2904\n",
      "\n",
      "Average test loss: 0.4295 Accuracy: 4264/ 5000 (85.28%)\n",
      "\n",
      "Epoch: 84\n",
      "[    0/45000 (  0%)] Loss: 0.3154\n",
      "[12800/45000 ( 28%)] Loss: 0.2328\n",
      "[25600/45000 ( 57%)] Loss: 0.3773\n",
      "[38400/45000 ( 85%)] Loss: 0.2532\n",
      "\n",
      "Average test loss: 0.5302 Accuracy: 4096/ 5000 (81.92%)\n",
      "\n",
      "Epoch: 85\n",
      "[    0/45000 (  0%)] Loss: 0.2937\n",
      "[12800/45000 ( 28%)] Loss: 0.2915\n",
      "[25600/45000 ( 57%)] Loss: 0.3029\n",
      "[38400/45000 ( 85%)] Loss: 0.2912\n",
      "\n",
      "Average test loss: 0.4965 Accuracy: 4162/ 5000 (83.24%)\n",
      "\n",
      "Epoch: 86\n",
      "[    0/45000 (  0%)] Loss: 0.3302\n",
      "[12800/45000 ( 28%)] Loss: 0.3299\n",
      "[25600/45000 ( 57%)] Loss: 0.3566\n",
      "[38400/45000 ( 85%)] Loss: 0.3886\n",
      "\n",
      "Average test loss: 0.5347 Accuracy: 4111/ 5000 (82.22%)\n",
      "\n",
      "Epoch: 87\n",
      "[    0/45000 (  0%)] Loss: 0.3507\n",
      "[12800/45000 ( 28%)] Loss: 0.2940\n",
      "[25600/45000 ( 57%)] Loss: 0.5319\n",
      "[38400/45000 ( 85%)] Loss: 0.3150\n",
      "\n",
      "Average test loss: 0.5090 Accuracy: 4133/ 5000 (82.66%)\n",
      "\n",
      "Epoch: 88\n",
      "[    0/45000 (  0%)] Loss: 0.2857\n",
      "[12800/45000 ( 28%)] Loss: 0.2566\n",
      "[25600/45000 ( 57%)] Loss: 0.3215\n",
      "[38400/45000 ( 85%)] Loss: 0.3552\n",
      "\n",
      "Average test loss: 0.4679 Accuracy: 4195/ 5000 (83.90%)\n",
      "\n",
      "Epoch: 89\n",
      "[    0/45000 (  0%)] Loss: 0.3782\n",
      "[12800/45000 ( 28%)] Loss: 0.3914\n",
      "[25600/45000 ( 57%)] Loss: 0.3575\n",
      "[38400/45000 ( 85%)] Loss: 0.3031\n",
      "\n",
      "Average test loss: 0.4732 Accuracy: 4168/ 5000 (83.36%)\n",
      "\n",
      "Epoch: 90\n",
      "[    0/45000 (  0%)] Loss: 0.3064\n",
      "[12800/45000 ( 28%)] Loss: 0.2318\n",
      "[25600/45000 ( 57%)] Loss: 0.1358\n",
      "[38400/45000 ( 85%)] Loss: 0.1522\n",
      "\n",
      "Average test loss: 0.4331 Accuracy: 4271/ 5000 (85.42%)\n",
      "\n",
      "Epoch: 91\n",
      "[    0/45000 (  0%)] Loss: 0.1760\n",
      "[12800/45000 ( 28%)] Loss: 0.2539\n",
      "[25600/45000 ( 57%)] Loss: 0.3061\n",
      "[38400/45000 ( 85%)] Loss: 0.3401\n",
      "\n",
      "Average test loss: 0.4427 Accuracy: 4269/ 5000 (85.38%)\n",
      "\n",
      "Epoch: 92\n",
      "[    0/45000 (  0%)] Loss: 0.2531\n",
      "[12800/45000 ( 28%)] Loss: 0.3091\n",
      "[25600/45000 ( 57%)] Loss: 0.2173\n",
      "[38400/45000 ( 85%)] Loss: 0.2987\n",
      "\n",
      "Average test loss: 0.7186 Accuracy: 3841/ 5000 (76.82%)\n",
      "\n",
      "Epoch: 93\n",
      "[    0/45000 (  0%)] Loss: 0.2599\n",
      "[12800/45000 ( 28%)] Loss: 0.3566\n",
      "[25600/45000 ( 57%)] Loss: 0.3583\n",
      "[38400/45000 ( 85%)] Loss: 0.2706\n",
      "\n",
      "Average test loss: 0.6241 Accuracy: 3990/ 5000 (79.80%)\n",
      "\n",
      "Epoch: 94\n",
      "[    0/45000 (  0%)] Loss: 0.4354\n",
      "[12800/45000 ( 28%)] Loss: 0.1785\n",
      "[25600/45000 ( 57%)] Loss: 0.2512\n",
      "[38400/45000 ( 85%)] Loss: 0.4123\n",
      "\n",
      "Average test loss: 0.4998 Accuracy: 4173/ 5000 (83.46%)\n",
      "\n",
      "Epoch: 95\n",
      "[    0/45000 (  0%)] Loss: 0.3792\n",
      "[12800/45000 ( 28%)] Loss: 0.2400\n",
      "[25600/45000 ( 57%)] Loss: 0.3680\n",
      "[38400/45000 ( 85%)] Loss: 0.2400\n",
      "\n",
      "Average test loss: 0.4582 Accuracy: 4252/ 5000 (85.04%)\n",
      "\n",
      "Epoch: 96\n",
      "[    0/45000 (  0%)] Loss: 0.2954\n",
      "[12800/45000 ( 28%)] Loss: 0.4222\n",
      "[25600/45000 ( 57%)] Loss: 0.2044\n",
      "[38400/45000 ( 85%)] Loss: 0.3258\n",
      "\n",
      "Average test loss: 0.5057 Accuracy: 4166/ 5000 (83.32%)\n",
      "\n",
      "Epoch: 97\n",
      "[    0/45000 (  0%)] Loss: 0.2736\n",
      "[12800/45000 ( 28%)] Loss: 0.1853\n",
      "[25600/45000 ( 57%)] Loss: 0.3901\n",
      "[38400/45000 ( 85%)] Loss: 0.2115\n",
      "\n",
      "Average test loss: 0.4690 Accuracy: 4199/ 5000 (83.98%)\n",
      "\n",
      "Epoch: 98\n",
      "[    0/45000 (  0%)] Loss: 0.2952\n",
      "[12800/45000 ( 28%)] Loss: 0.3084\n",
      "[25600/45000 ( 57%)] Loss: 0.2299\n",
      "[38400/45000 ( 85%)] Loss: 0.2969\n",
      "\n",
      "Average test loss: 0.4397 Accuracy: 4226/ 5000 (84.52%)\n",
      "\n",
      "Epoch: 99\n",
      "[    0/45000 (  0%)] Loss: 0.2005\n",
      "[12800/45000 ( 28%)] Loss: 0.4058\n",
      "[25600/45000 ( 57%)] Loss: 0.3581\n",
      "[38400/45000 ( 85%)] Loss: 0.2311\n",
      "\n",
      "Average test loss: 0.4540 Accuracy: 4178/ 5000 (83.56%)\n",
      "\n",
      "Epoch: 100\n",
      "[    0/45000 (  0%)] Loss: 0.2215\n",
      "[12800/45000 ( 28%)] Loss: 0.2387\n",
      "[25600/45000 ( 57%)] Loss: 0.2623\n",
      "[38400/45000 ( 85%)] Loss: 0.3057\n",
      "\n",
      "Average test loss: 0.4283 Accuracy: 4252/ 5000 (85.04%)\n",
      "\n",
      "Epoch: 101\n",
      "[    0/45000 (  0%)] Loss: 0.2503\n",
      "[12800/45000 ( 28%)] Loss: 0.2389\n",
      "[25600/45000 ( 57%)] Loss: 0.2679\n",
      "[38400/45000 ( 85%)] Loss: 0.2290\n",
      "\n",
      "Average test loss: 0.4342 Accuracy: 4225/ 5000 (84.50%)\n",
      "\n",
      "Epoch: 102\n",
      "[    0/45000 (  0%)] Loss: 0.2758\n",
      "[12800/45000 ( 28%)] Loss: 0.2647\n",
      "[25600/45000 ( 57%)] Loss: 0.2313\n",
      "[38400/45000 ( 85%)] Loss: 0.2534\n",
      "\n",
      "Average test loss: 0.4273 Accuracy: 4270/ 5000 (85.40%)\n",
      "\n",
      "Epoch: 103\n",
      "[    0/45000 (  0%)] Loss: 0.2264\n",
      "[12800/45000 ( 28%)] Loss: 0.2957\n",
      "[25600/45000 ( 57%)] Loss: 0.3285\n",
      "[38400/45000 ( 85%)] Loss: 0.2779\n",
      "\n",
      "Average test loss: 0.4695 Accuracy: 4198/ 5000 (83.96%)\n",
      "\n",
      "Epoch: 104\n",
      "[    0/45000 (  0%)] Loss: 0.2324\n",
      "[12800/45000 ( 28%)] Loss: 0.2881\n",
      "[25600/45000 ( 57%)] Loss: 0.1644\n",
      "[38400/45000 ( 85%)] Loss: 0.3400\n",
      "\n",
      "Average test loss: 0.4577 Accuracy: 4200/ 5000 (84.00%)\n",
      "\n",
      "Epoch: 105\n",
      "[    0/45000 (  0%)] Loss: 0.2444\n",
      "[12800/45000 ( 28%)] Loss: 0.2899\n",
      "[25600/45000 ( 57%)] Loss: 0.2843\n",
      "[38400/45000 ( 85%)] Loss: 0.3169\n",
      "\n",
      "Average test loss: 0.5218 Accuracy: 4111/ 5000 (82.22%)\n",
      "\n",
      "Epoch: 106\n",
      "[    0/45000 (  0%)] Loss: 0.2248\n",
      "[12800/45000 ( 28%)] Loss: 0.2888\n",
      "[25600/45000 ( 57%)] Loss: 0.1690\n",
      "[38400/45000 ( 85%)] Loss: 0.3336\n",
      "\n",
      "Average test loss: 0.4451 Accuracy: 4255/ 5000 (85.10%)\n",
      "\n",
      "Epoch: 107\n",
      "[    0/45000 (  0%)] Loss: 0.2830\n",
      "[12800/45000 ( 28%)] Loss: 0.2570\n",
      "[25600/45000 ( 57%)] Loss: 0.2740\n",
      "[38400/45000 ( 85%)] Loss: 0.2536\n",
      "\n",
      "Average test loss: 0.4462 Accuracy: 4214/ 5000 (84.28%)\n",
      "\n",
      "Epoch: 108\n",
      "[    0/45000 (  0%)] Loss: 0.2133\n",
      "[12800/45000 ( 28%)] Loss: 0.2084\n",
      "[25600/45000 ( 57%)] Loss: 0.2881\n",
      "[38400/45000 ( 85%)] Loss: 0.3215\n",
      "\n",
      "Average test loss: 0.4334 Accuracy: 4238/ 5000 (84.76%)\n",
      "\n",
      "Epoch: 109\n",
      "[    0/45000 (  0%)] Loss: 0.2001\n",
      "[12800/45000 ( 28%)] Loss: 0.2666\n",
      "[25600/45000 ( 57%)] Loss: 0.2757\n",
      "[38400/45000 ( 85%)] Loss: 0.1869\n",
      "\n",
      "Average test loss: 0.5470 Accuracy: 4098/ 5000 (81.96%)\n",
      "\n",
      "Epoch: 110\n",
      "[    0/45000 (  0%)] Loss: 0.2583\n",
      "[12800/45000 ( 28%)] Loss: 0.1979\n",
      "[25600/45000 ( 57%)] Loss: 0.2732\n",
      "[38400/45000 ( 85%)] Loss: 0.3303\n",
      "\n",
      "Average test loss: 0.4048 Accuracy: 4340/ 5000 (86.80%)\n",
      "\n",
      "Epoch: 111\n",
      "[    0/45000 (  0%)] Loss: 0.2404\n",
      "[12800/45000 ( 28%)] Loss: 0.2156\n",
      "[25600/45000 ( 57%)] Loss: 0.2353\n",
      "[38400/45000 ( 85%)] Loss: 0.2231\n",
      "\n",
      "Average test loss: 0.5053 Accuracy: 4138/ 5000 (82.76%)\n",
      "\n",
      "Epoch: 112\n",
      "[    0/45000 (  0%)] Loss: 0.2557\n",
      "[12800/45000 ( 28%)] Loss: 0.2149\n",
      "[25600/45000 ( 57%)] Loss: 0.1548\n",
      "[38400/45000 ( 85%)] Loss: 0.2672\n",
      "\n",
      "Average test loss: 0.4618 Accuracy: 4212/ 5000 (84.24%)\n",
      "\n",
      "Epoch: 113\n",
      "[    0/45000 (  0%)] Loss: 0.3571\n",
      "[12800/45000 ( 28%)] Loss: 0.1478\n",
      "[25600/45000 ( 57%)] Loss: 0.2187\n",
      "[38400/45000 ( 85%)] Loss: 0.1652\n",
      "\n",
      "Average test loss: 0.3748 Accuracy: 4335/ 5000 (86.70%)\n",
      "\n",
      "Epoch: 114\n",
      "[    0/45000 (  0%)] Loss: 0.1875\n",
      "[12800/45000 ( 28%)] Loss: 0.2676\n",
      "[25600/45000 ( 57%)] Loss: 0.1525\n",
      "[38400/45000 ( 85%)] Loss: 0.1950\n",
      "\n",
      "Average test loss: 0.4466 Accuracy: 4234/ 5000 (84.68%)\n",
      "\n",
      "Epoch: 115\n",
      "[    0/45000 (  0%)] Loss: 0.2235\n",
      "[12800/45000 ( 28%)] Loss: 0.2036\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = np.inf  # Track the highest validation accuracy\n",
    "\n",
    "start_time = time.time()\n",
    "train_loss_history, valid_loss_history = [], []\n",
    "termination_count = 0 #If valid loss does not decrease in 5 consecutive epochs terminate the training\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  print('Epoch:', epoch)\n",
    "  train_epoch(model, optimizer, scheduler, train_loader, train_loss_history, criterion)\n",
    "  evaluate(model, validation_loader, valid_loss_history, criterion)\n",
    "  if valid_loss_history[-1] < best_val_loss:\n",
    "  #Save the best model in terms of validation loss.\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    best_val_loss = valid_loss_history[-1]\n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlGkSTbXnJ5t"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gNh2mxzj1A2"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYXa9uWcmMTY"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss_history,'-',linewidth=3,label='Train error')\n",
    "plt.plot(valid_loss_history,'-',linewidth=3,label='Validation error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "%matplotlib inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDIQlkT7xovA",
    "outputId": "af51279b-9f21-4aa8-8ca8-6449a0c9a875"
   },
   "outputs": [],
   "source": [
    "evaluate(model, test_loader, [], criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEdBcwR4kGRd"
   },
   "source": [
    "# Predict labels for nonlabeled dataset and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPnMLwXeDR4r"
   },
   "outputs": [],
   "source": [
    "def predict_labels(model, data_loader):\n",
    "  model.eval()\n",
    "  predicted_labels = []\n",
    "  ids = []\n",
    "  with torch.no_grad():\n",
    "    for data, id in data_loader:\n",
    "      data = data.to(device)\n",
    "      output = model(data)\n",
    "      _, pred = torch.max(output, dim=1)\n",
    "      predicted_labels = predicted_labels + pred.tolist()\n",
    "      ids = ids + id.tolist()\n",
    "  df = pd.DataFrame({\n",
    "    'ID': ids,\n",
    "    'Labels': predicted_labels\n",
    "})\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-5KRy9SHqvK"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "unlabeled_testset = CIFAR10Dataset(unlabeled_set_dir, train=False, unlabeled=True, transform=transform)\n",
    "unlabeled_test_loader = torch.utils.data.DataLoader(unlabeled_testset,batch_size=BATCH_SIZE_TEST,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzQw8ijLJZHI"
   },
   "outputs": [],
   "source": [
    "df = predict_labels(model, unlabeled_test_loader)\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
