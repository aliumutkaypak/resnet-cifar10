{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VIi6JeghfA0"
   },
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6oL5rmU684KS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rh1RE49dk46A"
   },
   "source": [
    "# Define inference arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "daazjLZok4ey"
   },
   "outputs": [],
   "source": [
    "# Dataset directories\n",
    "labeled_set_dir = 'data/cifar-10-batches-py'\n",
    "unlabeled_set_dir = 'data'\n",
    "\n",
    "# Output csv file\n",
    "output_csv_path = 'output.csv'\n",
    "\n",
    "# Checkpoint path\n",
    "checkpoint_path = 'model_5.pth'\n",
    "\n",
    "# Model hyperparameters\n",
    "blocks_in_layers = [4, 5, 4, 3]\n",
    "num_layers = 4\n",
    "dr= 0.0 \n",
    "num_channels= [32, 64, 128, 256]\n",
    "avg_pool_kernel_s=4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRxu_aQVhnoz"
   },
   "source": [
    "# Define CIFAR10 Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9sIFWbEE7MAS"
   },
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data_dir, train=True, unlabeled=False, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.unlabeled = unlabeled\n",
    "        # Load all data batches\n",
    "        if unlabeled:\n",
    "          self.data, self.id = self.load_unlabeled_data()\n",
    "          self.labels = None\n",
    "        else:\n",
    "          self.data, self.labels = self.load_labeled_data()\n",
    "\n",
    "    def load_cifar_batch(self, file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            batch = pickle.load(fo, encoding='bytes')\n",
    "        return batch\n",
    "\n",
    "    def load_labeled_data(self):\n",
    "        data_batches = []\n",
    "        label_batches = []\n",
    "        if self.train:\n",
    "          for i in range(1, 6):\n",
    "            batch_file = os.path.join(self.data_dir, f'data_batch_{i}')\n",
    "            batch = self.load_cifar_batch(batch_file)\n",
    "            data_batches.append(batch[b'data'])\n",
    "            label_batches += batch[b'labels']\n",
    "        else:\n",
    "          batch_file = os.path.join(self.data_dir, f'test_batch')\n",
    "          batch = self.load_cifar_batch(batch_file)\n",
    "          data_batches.append(batch[b'data'])\n",
    "          label_batches += batch[b'labels']\n",
    "\n",
    "        data = np.vstack(data_batches).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "        labels = np.array(label_batches)\n",
    "        return data, labels\n",
    "\n",
    "    def load_unlabeled_data(self):\n",
    "        # Load the unlabeled batch\n",
    "        batch_file = os.path.join(self.data_dir, 'cifar_test_nolabels.pkl')\n",
    "        batch = self.load_cifar_batch(batch_file)\n",
    "        data = batch[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "        id = batch[b'ids'].tolist()\n",
    "        return data, id\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.unlabeled:\n",
    "          return len(self.labels)\n",
    "        else:\n",
    "          return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img = self.data[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if not self.unlabeled:\n",
    "          label = self.labels[idx]\n",
    "          return img, label\n",
    "        else:\n",
    "          return img, self.id[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NUrv6SCh0UW"
   },
   "source": [
    "# Define Resnet class. Changed version of the Resnet class in this repo: https://github.com/kuangliu/pytorch-cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lNSnNUnKi_d6"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "  expansion = 1\n",
    "\n",
    "  def __init__(self, in_planes, planes, stride=1):\n",
    "    super(BasicBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(\n",
    "        in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                            stride=1, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    self.shortcut = nn.Sequential()\n",
    "    if stride != 1 or in_planes != self.expansion*planes:\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                      kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(self.expansion*planes)\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.bn2(self.conv2(out))\n",
    "    out += self.shortcut(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "  def __init__(self, block, num_blocks, num_layers = 4, dropout= 0.3 ,num_channels=[64, 128, 256, 512] , avg_pool_kernel_s=4, num_classes=10):\n",
    "    super(ResNet, self).__init__()\n",
    "    assert len(num_channels) == num_layers\n",
    "    assert len(num_blocks) == num_layers\n",
    "    self.in_planes = 64\n",
    "    self.avg_pool_kernel_s = avg_pool_kernel_s\n",
    "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                            stride=1, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(64)\n",
    "    layers = []\n",
    "    for i in range(num_layers):\n",
    "      stride = 1 if i == 0 else 2\n",
    "      layers.append(nn.Dropout2d(p=dropout))\n",
    "      layers.append( self._make_layer(block, num_channels[i], num_blocks[i], stride=stride))\n",
    "    self.layers = nn.Sequential(*layers)\n",
    "    self.linear = nn.Linear(num_channels[-1]*block.expansion, num_classes)\n",
    "\n",
    "  def _make_layer(self, block, planes, num_blocks, stride):\n",
    "    strides = [stride] + [1]*(num_blocks-1)\n",
    "    layers = []\n",
    "    for stride in strides:\n",
    "        layers.append(block(self.in_planes, planes, stride))\n",
    "        self.in_planes = planes * block.expansion\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.layers(out)\n",
    "    out = F.avg_pool2d(out, self.avg_pool_kernel_s)\n",
    "    out = out.view(out.size(0), -1)\n",
    "    out = self.linear(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ENMDE4tx12x",
    "outputId": "47812efb-6877-4102-c4f0-85b1e41d8ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# If GPU available, the code uses it. Otherwise cpu is used for the training (not recommended).\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODmBAwVGw784"
   },
   "source": [
    "# Load dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RDmaYw8Rohnk"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_TEST = 1000\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = CIFAR10Dataset(labeled_set_dir, train=True, unlabeled=False, transform=transform)\n",
    "testset = CIFAR10Dataset(labeled_set_dir, train=False, unlabeled=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4un-sO_ijpm"
   },
   "source": [
    "## Create validation set from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5kVGBCe1vvPd"
   },
   "outputs": [],
   "source": [
    "total_size = len(trainset)\n",
    "train_size = int(0.9 * total_size)\n",
    "validation_size = total_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "trainset, validationset = torch.utils.data.random_split(trainset, [train_size, validation_size], generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqWZRKC6itri"
   },
   "source": [
    "## Create dataloader instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9btjqfl5yq6W"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE_TRAIN,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE_TEST,shuffle=False)\n",
    "validation_loader = torch.utils.data.DataLoader(validationset,batch_size=BATCH_SIZE_TRAIN,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cuwl03CkizmT"
   },
   "source": [
    "# Define evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LtmwnJgk06_N"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, loss_history, criterion, set_name='test'):\n",
    "  model.eval()\n",
    "  total_samples = len(data_loader.dataset)\n",
    "  correct_samples = 0\n",
    "  losses = []\n",
    "  with torch.no_grad():\n",
    "    for data, target in data_loader:\n",
    "      data = data.to(device)\n",
    "      target = target.to(device)\n",
    "      output = model(data)\n",
    "      loss = criterion(output, target)\n",
    "      _, pred = torch.max(output, dim=1)\n",
    "\n",
    "      losses.append(loss.item())\n",
    "      correct_samples += pred.eq(target).sum()\n",
    "\n",
    "  avg_loss = np.mean(losses)\n",
    "  loss_history.append(avg_loss)\n",
    "  print('\\nAverage '+ set_name + ' loss: ' + '{:.4f}'.format(avg_loss) +\n",
    "  ' Accuracy:' + '{:5}'.format(correct_samples) + '/' + '{:5}'.format(total_samples) + ' (' +\n",
    "  '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uia6PwY4jFEg"
   },
   "source": [
    "# Create model and upload checkpoint\n",
    "Note that the created model and the checkpoint should be in the shape.\\\n",
    "Check the ReadMe file to learn the model shapes of the checkpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ouhj4UI2RLS",
    "outputId": "18a9904b-3c36-4d3c-dea5-4cae64bab6d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "         Dropout2d-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 32, 32, 32]          18,432\n",
      "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
      "            Conv2d-6           [-1, 32, 32, 32]           9,216\n",
      "       BatchNorm2d-7           [-1, 32, 32, 32]              64\n",
      "            Conv2d-8           [-1, 32, 32, 32]           2,048\n",
      "       BatchNorm2d-9           [-1, 32, 32, 32]              64\n",
      "       BasicBlock-10           [-1, 32, 32, 32]               0\n",
      "           Conv2d-11           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-12           [-1, 32, 32, 32]              64\n",
      "           Conv2d-13           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-14           [-1, 32, 32, 32]              64\n",
      "       BasicBlock-15           [-1, 32, 32, 32]               0\n",
      "           Conv2d-16           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-17           [-1, 32, 32, 32]              64\n",
      "           Conv2d-18           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-19           [-1, 32, 32, 32]              64\n",
      "       BasicBlock-20           [-1, 32, 32, 32]               0\n",
      "           Conv2d-21           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-22           [-1, 32, 32, 32]              64\n",
      "           Conv2d-23           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-24           [-1, 32, 32, 32]              64\n",
      "       BasicBlock-25           [-1, 32, 32, 32]               0\n",
      "        Dropout2d-26           [-1, 32, 32, 32]               0\n",
      "           Conv2d-27           [-1, 64, 16, 16]          18,432\n",
      "      BatchNorm2d-28           [-1, 64, 16, 16]             128\n",
      "           Conv2d-29           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-30           [-1, 64, 16, 16]             128\n",
      "           Conv2d-31           [-1, 64, 16, 16]           2,048\n",
      "      BatchNorm2d-32           [-1, 64, 16, 16]             128\n",
      "       BasicBlock-33           [-1, 64, 16, 16]               0\n",
      "           Conv2d-34           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-35           [-1, 64, 16, 16]             128\n",
      "           Conv2d-36           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-37           [-1, 64, 16, 16]             128\n",
      "       BasicBlock-38           [-1, 64, 16, 16]               0\n",
      "           Conv2d-39           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-40           [-1, 64, 16, 16]             128\n",
      "           Conv2d-41           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-42           [-1, 64, 16, 16]             128\n",
      "       BasicBlock-43           [-1, 64, 16, 16]               0\n",
      "           Conv2d-44           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-45           [-1, 64, 16, 16]             128\n",
      "           Conv2d-46           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-47           [-1, 64, 16, 16]             128\n",
      "       BasicBlock-48           [-1, 64, 16, 16]               0\n",
      "           Conv2d-49           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-50           [-1, 64, 16, 16]             128\n",
      "           Conv2d-51           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-52           [-1, 64, 16, 16]             128\n",
      "       BasicBlock-53           [-1, 64, 16, 16]               0\n",
      "        Dropout2d-54           [-1, 64, 16, 16]               0\n",
      "           Conv2d-55            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-56            [-1, 128, 8, 8]             256\n",
      "           Conv2d-57            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-58            [-1, 128, 8, 8]             256\n",
      "           Conv2d-59            [-1, 128, 8, 8]           8,192\n",
      "      BatchNorm2d-60            [-1, 128, 8, 8]             256\n",
      "       BasicBlock-61            [-1, 128, 8, 8]               0\n",
      "           Conv2d-62            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 8, 8]             256\n",
      "           Conv2d-64            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-65            [-1, 128, 8, 8]             256\n",
      "       BasicBlock-66            [-1, 128, 8, 8]               0\n",
      "           Conv2d-67            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-68            [-1, 128, 8, 8]             256\n",
      "           Conv2d-69            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-70            [-1, 128, 8, 8]             256\n",
      "       BasicBlock-71            [-1, 128, 8, 8]               0\n",
      "           Conv2d-72            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 8, 8]             256\n",
      "           Conv2d-74            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-75            [-1, 128, 8, 8]             256\n",
      "       BasicBlock-76            [-1, 128, 8, 8]               0\n",
      "        Dropout2d-77            [-1, 128, 8, 8]               0\n",
      "           Conv2d-78            [-1, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-79            [-1, 256, 4, 4]             512\n",
      "           Conv2d-80            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-81            [-1, 256, 4, 4]             512\n",
      "           Conv2d-82            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-83            [-1, 256, 4, 4]             512\n",
      "       BasicBlock-84            [-1, 256, 4, 4]               0\n",
      "           Conv2d-85            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-86            [-1, 256, 4, 4]             512\n",
      "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-88            [-1, 256, 4, 4]             512\n",
      "       BasicBlock-89            [-1, 256, 4, 4]               0\n",
      "           Conv2d-90            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-91            [-1, 256, 4, 4]             512\n",
      "           Conv2d-92            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
      "       BasicBlock-94            [-1, 256, 4, 4]               0\n",
      "           Linear-95                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 4,840,458\n",
      "Trainable params: 4,840,458\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 12.72\n",
      "Params size (MB): 18.46\n",
      "Estimated Total Size (MB): 31.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock,\n",
    "               blocks_in_layers, \n",
    "               num_layers = num_layers, \n",
    "               dropout=dr,\n",
    "               num_channels=num_channels, \n",
    "               avg_pool_kernel_s=avg_pool_kernel_s, \n",
    "               num_classes=10)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YlGkSTbXnJ5t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Dropout2d(p=0.0, inplace=False)\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (2): Dropout2d(p=0.0, inplace=False)\n",
       "    (3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (4): Dropout2d(p=0.0, inplace=False)\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (6): Dropout2d(p=0.0, inplace=False)\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gNh2mxzj1A2"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDIQlkT7xovA",
    "outputId": "af51279b-9f21-4aa8-8ca8-6449a0c9a875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average test loss: 0.1656 Accuracy: 9523/10000 (95.23%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_loader, [], criterion, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average train loss: 0.0024 Accuracy:44993/45000 (99.98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, train_loader, [], criterion, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average validation loss: 0.1434 Accuracy: 4786/ 5000 (95.72%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, validation_loader, [], criterion, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEdBcwR4kGRd"
   },
   "source": [
    "# Predict labels for nonlabeled dataset and save the results to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MPnMLwXeDR4r"
   },
   "outputs": [],
   "source": [
    "def predict_labels(model, data_loader):\n",
    "  model.eval()\n",
    "  predicted_labels = []\n",
    "  ids = []\n",
    "  with torch.no_grad():\n",
    "    for data, id in data_loader:\n",
    "      data = data.to(device)\n",
    "      output = model(data)\n",
    "      _, pred = torch.max(output, dim=1)\n",
    "      predicted_labels = predicted_labels + pred.tolist()\n",
    "      ids = ids + id.tolist()\n",
    "  df = pd.DataFrame({\n",
    "    'ID': ids,\n",
    "    'Labels': predicted_labels\n",
    "})\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6-5KRy9SHqvK"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "unlabeled_testset = CIFAR10Dataset(unlabeled_set_dir, train=False, unlabeled=True, transform=transform)\n",
    "unlabeled_test_loader = torch.utils.data.DataLoader(unlabeled_testset,batch_size=BATCH_SIZE_TEST,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FzQw8ijLJZHI"
   },
   "outputs": [],
   "source": [
    "df = predict_labels(model, unlabeled_test_loader)\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
